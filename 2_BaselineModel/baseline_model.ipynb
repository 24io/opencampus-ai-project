{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "## Table of Contents\n",
    "1. [Model Choice](#model-choice)\n",
    "2. [Feature Selection](#feature-selection)\n",
    "3. [Implementation](#implementation)\n",
    "4. [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install tensorflow[and-cuda] argparse setuptools nunmpy matplotlib scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "\n",
    "from keras.models import load_model, Model, Input, optimizers\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, BatchNormalization, ZeroPadding2D\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choice\n",
    "\n",
    "[Explain why you've chosen a particular model as the baseline. This could be a simple statistical model or a basic machine learning model. Justify your choice.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "[Indicate which features from the dataset you will be using for the baseline model, and justify your selection.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "[Implement your baseline model here.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class\n",
    "class Baseline(Model):\n",
    "    def __init(self, input_shape):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.input_shape = Input(shape=input_shape)\n",
    "\n",
    "        # First bottleneck unit\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.activation1 = Activation('selu')\n",
    "        self.conv1 = Conv2D(32, kernel_size=(5, 5), padding='same', kernel_regularizer=l2(0.02))\n",
    "        \n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.activation2 = Activation('selu')\n",
    "        self.conv2 = Conv2D(128, kernel_size=(3, 3), padding='same', kernel_regularizer=l2(0.02))\n",
    "        \n",
    "        # Corner detection\n",
    "        self.bn3 = BatchNormalization()\n",
    "        self.padding = ZeroPadding2D(padding=(0, 3))\n",
    "        self.conv3 = Conv2D(32, kernel_size=(21, 7), padding='valid', activation='tanh')\n",
    "        self.conv4 = Conv2D(128, kernel_size=(1, 3), padding='same', activation='tanh')\n",
    "        \n",
    "        # Fully-connected predictor\n",
    "        self.flat = Flatten()\n",
    "        self.classify = Dense(512, activation='sigmoid')\n",
    "        self.dropout = Dropout(0.1)\n",
    "        self.result = Dense(input_shape[1], activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # First bottleneck unit\n",
    "        x = self.bn1(inputs)\n",
    "        x = self.activation_1(x)\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = self.bn2(x)\n",
    "        x = self.activation_2(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        merged = tf.keras.layers.add([inputs, x])\n",
    "        \n",
    "        # Corner detection\n",
    "        x = self.bn3(merged)\n",
    "        x = self.padding(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        # Fully-connected predictor\n",
    "        x = self.flat(x)\n",
    "        x = self.classify(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.result(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Eraly Stopping and Model Checkpointing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tbd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "[Clearly state what metrics you will use to evaluate the model's performance. These metrics will serve as a starting point for evaluating more complex models later on.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the baseline model\n",
    "# Example for a classification problem\n",
    "# y_pred = model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# For a regression problem, you might use:\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Your evaluation code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web3venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
