{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "2ed19b46543b95f6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T13:44:30.469822Z",
     "start_time": "2024-06-25T13:44:30.463561Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "import h5py\n",
    "import random\n",
    "import datetime\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.linalg import cond\n",
    "from typing import List\n",
    "\n",
    "# Matrixlib\n",
    "\n",
    "import matrixlib.block as blk\n",
    "from matrixlib import preconditioning as prec\n",
    "from matrixlib.core import MatrixData, ValueProperties, BlockProperties\n",
    "\n",
    "# Modellib\n",
    "import modellib.gcn\n",
    "import modellib.io\n",
    "import modellib.train\n",
    "import modellib.evaluate \n",
    "import modellib.losses"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T13:42:22.268404Z",
     "start_time": "2024-06-25T13:42:22.262078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Def constants and variables\n",
    "NUM_NODES = 64\n",
    "NUM_FEATURES = 21\n",
    "\n",
    "class_weights = {0: 0.2, 1: 0.8}"
   ],
   "id": "4173fc70eda8ec4b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Data",
   "id": "3b519ed7e3b16f0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T13:44:45.834855Z",
     "start_time": "2024-06-25T13:44:45.787022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "importlib.reload(modellib.io)\n",
    "\n",
    "# Load data\n",
    "train_bands, train_labels = modellib.io.load_from_hdf5('train.h5')\n",
    "val_bands, val_labels = modellib.io.load_from_hdf5('val.h5')\n",
    "test_bands, test_labels = modellib.io.load_from_hdf5('test.h5')\n",
    "\n",
    "# Reshape\n",
    "train_reshaped = np.squeeze(train_bands).transpose(0, 2, 1)\n",
    "val_reshaped = np.squeeze(val_bands).transpose(0, 2, 1)\n",
    "test_reshaped = np.squeeze(test_bands).transpose(0, 2, 1)\n",
    "\n",
    "# Create initial adj & normalize\n",
    "adj_matrix = modellib.gcn.create_initial_adj_matrix(NUM_NODES)\n",
    "adj_matrix = adj_matrix / np.sum(adj_matrix, axis=1, keepdims=True)\n",
    "\n",
    "# Repeat adj_matrix for each sample in train, val, and test sets\n",
    "adj_matrix_train = np.repeat(adj_matrix[np.newaxis, :, :], train_reshaped.shape[0], axis=0)\n",
    "adj_matrix_val = np.repeat(adj_matrix[np.newaxis, :, :], val_reshaped.shape[0], axis=0)\n",
    "adj_matrix_test = np.repeat(adj_matrix[np.newaxis, :, :], test_reshaped.shape[0], axis=0)"
   ],
   "id": "c5bbd7c1747c0ad0",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Reshape\u001B[39;00m\n\u001B[1;32m      9\u001B[0m train_reshaped \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msqueeze(train_bands)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m val_reshaped \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[43mval_bands\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m test_reshaped \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msqueeze(test_bands)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Create initial adj & normalize\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: axes don't match array"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "# Create Model \n",
    "model = modellib.gcn.create_gcn_model(NUM_NODES, NUM_FEATURES)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=lambda y_true, y_pred: modellib.losses.weighted_binary_crossentropy(y_true, y_pred, class_weights),\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        'recall'\n",
    "    ]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [train_reshaped, adj_matrix_train],\n",
    "    train_labels,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=([val_reshaped, adj_matrix_val], val_labels),\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_proba = model.predict([test_reshaped, adj_matrix_test])\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)  # Convert probabilities to binary predictions\n"
   ],
   "id": "d7d68d36fde41a55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Generate Data\n",
    "\n"
   ],
   "id": "7a21827df47d11a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def reshape_bands(matrixbands):\n",
    "    return np.squeeze(matrixbands).transpose(0, 2, 1)\n",
    "\n",
    "bands_reshaped = reshape_bands(bands)\n",
    "print(f\"Reshaped bands shape: {bands_reshaped.shape}\")\n",
    "\n",
    "def create_initial_adj_matrix(num_nodes, window_size=3):\n",
    "    adj_matrix = np.zeros((num_nodes, num_nodes))\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(max(0, i-window_size), min(num_nodes, i+window_size+1)):\n",
    "            adj_matrix[i, j] = 1\n",
    "    return adj_matrix\n",
    "\n",
    "num_nodes = MATRIX_DIM\n",
    "num_features = DIAGONAL_BAND_RADIUS * 2 + 1\n",
    "\n",
    "# Create and normalize adjacency matrix\n",
    "adj_matrix = create_initial_adj_matrix(num_nodes)\n",
    "adj_matrix = adj_matrix / np.sum(adj_matrix, axis=1, keepdims=True)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train = bands_reshaped[:train_size]\n",
    "X_val = bands_reshaped[train_size:train_size + val_size]\n",
    "X_test = bands_reshaped[train_size + val_size:]\n",
    "y_train = labels[:train_size]\n",
    "y_val = labels[train_size:train_size + val_size]\n",
    "y_test = labels[train_size + val_size:]\n",
    "\n",
    "# Repeat adj_matrix for each sample in train, val, and test sets\n",
    "adj_matrix_train = np.repeat(adj_matrix[np.newaxis, :, :], X_train.shape[0], axis=0)\n",
    "adj_matrix_val = np.repeat(adj_matrix[np.newaxis, :, :], X_val.shape[0], axis=0)\n",
    "adj_matrix_test = np.repeat(adj_matrix[np.newaxis, :, :], X_test.shape[0], axis=0)\n",
    "\n",
    "\n",
    "class GraphConv(layers.Layer):\n",
    "    def __init__(self, units, activation=None):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[0][-1], self.units),\n",
    "            initializer='glorot_uniform',\n",
    "            name='kernel')\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer='zeros', name='bias')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        h = tf.matmul(x, self.w)\n",
    "        h = tf.matmul(a, h)\n",
    "        out = h + self.b\n",
    "        return self.activation(out) if self.activation is not None else out\n",
    "\n",
    "def create_gcn_model(num_nodes, num_features):\n",
    "    x_input = Input(shape=(num_nodes, num_features))\n",
    "    a_input = Input(shape=(num_nodes, num_nodes))\n",
    "\n",
    "    gc1 = GraphConv(64, activation='relu')([x_input, a_input])\n",
    "    gc2 = GraphConv(32, activation='relu')([gc1, a_input])\n",
    "    gc3 = GraphConv(1)([gc2, a_input])\n",
    "\n",
    "    output = layers.Flatten()(gc3)\n",
    "    output = layers.Dense(num_nodes, activation='sigmoid')(output)\n",
    "\n",
    "    model = Model(inputs=[x_input, a_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "model = create_gcn_model(num_nodes, num_features)\n",
    "# Compile the model with appropriate loss and metrics\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        'recall'\n",
    "    ]\n",
    ")\n",
    "from tensorflow.keras.utils import compute_class_weight\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "# Use the class weights in model.fit()\n",
    "history = model.fit(\n",
    "    [X_train, adj_matrix_train],\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=([X_val, adj_matrix_val], y_val),\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_proba = model.predict([X_test, adj_matrix_test])\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='samples', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='samples', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='samples', zero_division=0)\n",
    "\n",
    "# Calculate confusion matrix for each label\n",
    "mcm = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate overall TP and FN\n",
    "tp = np.sum([cm[1, 1] for cm in mcm])\n",
    "fn = np.sum([cm[1, 0] for cm in mcm])\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"True Positives: {tp}\")\n",
    "print(f\"False Negatives: {fn}\")"
   ],
   "id": "3d1e0395a28d7922"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matrix Venv",
   "language": "python",
   "name": "matrix_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
