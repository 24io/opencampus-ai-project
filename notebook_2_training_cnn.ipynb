{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "import datetime\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Modellib\n",
    "import modellib.cnn\n",
    "import modellib.train\n",
    "import modellib.io as io\n",
    "import modellib.evaluate as eval"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load and transform matrix datasets"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reading the datasets\n",
    "train_bands, train_labels = io.read_from_hdf5(\"data/datasets/train_dataset_64_1600.h5\")\n",
    "val_bands, val_labels = io.read_from_hdf5(\"data/datasets/val_dataset_64_200.h5\")\n",
    "test_bands, test_labels = io.read_from_hdf5(\"data/datasets/test_dataset_64_200.h5\")\n",
    "\n",
    "# Printing shapes to verify\n",
    "print(f\"Train bands shape: {train_bands.shape}, Train labels shape: {train_labels.shape}\")\n",
    "print(f\"Validation bands shape: {val_bands.shape}, Validation labels shape: {val_labels.shape}\")\n",
    "print(f\"Test bands shape: {test_bands.shape}, Test labels shape: {test_labels.shape}\")\n",
    "\n",
    "# Convert to tensorflow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_bands, train_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_bands, val_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_bands, test_labels))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "run tensorboard --logdir logs to launch tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create log dir\n",
    "log_dir = \"logs/cnn/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "print(\"Files in log directory:\", os.listdir(log_dir))\n",
    "\n",
    "# Create Learning Rate scheduler\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.00001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "\n",
    "# Define parameters\n",
    "batch_size = 16\n",
    "num_epochs = 200\n",
    "input_shape = (21, 64, 1)\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=lr_schedule)\n",
    "class_weights = {0: 0.2, 1: 0.8}\n",
    "\n",
    "# Create and Compile Model\n",
    "model = modellib.cnn.create_compile_model_custom_loss(\n",
    "    input_shape, \n",
    "    optimizer, \n",
    "    class_weights\n",
    ")\n",
    "\n",
    "# Start Training Loop\n",
    "trained_model, train_losses, val_losses = modellib.train.train_model(\n",
    "    model,\n",
    "    train_dataset.batch(batch_size),  \n",
    "    val_dataset.batch(batch_size),\n",
    "    num_epochs,\n",
    "    log_dir\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot losses\n",
    "modellib.train.plot_losses(train_losses, val_losses)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Evaluate the model on the test set\n",
    "evaluation_results = modellib.evaluate.evaluate_model(\n",
    "    trained_model,\n",
    "    test_dataset.batch(batch_size),\n",
    "    class_weights\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Restore Best Model Weights"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Restore weights from best run\n",
    "new_model = modellib.cnn.Baseline(input_shape)\n",
    "new_model.build((None,) + input_shape)  # None represents the batch dimension\n",
    "new_model.load_weights(\"cnn.weights.h5\")\n",
    "\n",
    "# print weights\n",
    "print(f\"Model Weights: {new_model.get_weights()}\")\n",
    "\n",
    "# Evaluate the restored model\n",
    "new_results = modellib.evaluate.evaluate_model(\n",
    "    new_model,\n",
    "    test_dataset.batch(batch_size),\n",
    "    class_weights\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Make Predictions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "importlib.reload(eval)\n",
    "test_predictions = new_model.predict(test_dataset.batch(batch_size))\n",
    "\n",
    "# Convert to Binary\n",
    "threshold = 0.5\n",
    "binary_predictions = (test_predictions >= threshold).astype(int)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save predictions\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save predictions \n",
    "np.save('test_predictions.npy', binary_predictions)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load predictions and print to verify\n",
    "loaded_predictions = np.load('test_predictions.npy')\n",
    "print(loaded_predictions)\n",
    "\n",
    "# Evaluate to verify\n",
    "metrics = eval.calculate_metrics(test_labels, loaded_predictions)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
